{"cells":[{"cell_type":"markdown","metadata":{"id":"oc5jNi98cZ5A"},"source":["## Get the data file"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"w-x9de9Bcrs2","executionInfo":{"status":"ok","timestamp":1751767376548,"user_tz":-600,"elapsed":6,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":["device = 'cuda'\n"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"1ZbFkbTzcrvy","executionInfo":{"status":"ok","timestamp":1751767376968,"user_tz":-600,"elapsed":4,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"eD-2yEQGcZ5E","executionInfo":{"status":"ok","timestamp":1751767377332,"user_tz":-600,"elapsed":4,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":[]},{"cell_type":"code","execution_count":4,"metadata":{"id":"nH9zLxUFcZ5G","executionInfo":{"status":"ok","timestamp":1751767471899,"user_tz":-600,"elapsed":78,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":["file_path =  \"spa.txt\"\n","\n","with open(file_path, encoding=\"utf-8\") as f:\n","    lines = f.read().strip().split(\"\\n\")"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"Z7H2cRy0cZ5I","executionInfo":{"status":"ok","timestamp":1751767472599,"user_tz":-600,"elapsed":5,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":["def clean_pair(line):\n","    parts = line.strip().split(\"\\t\")\n","\n","    if len(parts) < 2:\n","        print(f\"PROBLEM: {line}\")\n","        return None\n","    eng = parts[0].strip()\n","    spa = parts[1].strip().split(\"CC-BY\")[0].strip()  # Remove attribution text\n","    return eng, spa"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"wB5Ses8KcZ5J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1751767473076,"user_tz":-600,"elapsed":196,"user":{"displayName":"William Cable","userId":"04663351666127960465"}},"outputId":"e44f84c5-63fc-4f76-f71d-209076116776"},"outputs":[{"output_type":"stream","name":"stdout","text":["PROBLEM: The last piece of cake wa\n"]}],"source":["clean_pairs = [clean_pair(line) for line in lines]\n","clean_pairs = [pair for pair in clean_pairs if pair is not None]\n","clean_pairs = clean_pairs #TEMP FOR TESTING (WILL BRICK PC)"]},{"cell_type":"code","source":[],"metadata":{"id":"G_mylgdOeTL_","executionInfo":{"status":"ok","timestamp":1751767473457,"user_tz":-600,"elapsed":33,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30,"status":"ok","timestamp":1751767473490,"user":{"displayName":"William Cable","userId":"04663351666127960465"},"user_tz":-600},"id":"rPhmOFIVcZ5K","outputId":"9e9d2388-5911-41e3-8a00-6705004034bb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Go.', 'Ve.'),\n"," ('Go.', 'Vete.'),\n"," ('Go.', 'Vaya.'),\n"," ('Go.', 'Váyase.'),\n"," ('Hi.', 'Hola.'),\n"," ('Run!', '¡Corre!'),\n"," ('Run!', '¡Corran!'),\n"," ('Run!', '¡Huye!'),\n"," ('Run!', '¡Corra!'),\n"," ('Run!', '¡Corred!')]"]},"metadata":{},"execution_count":7}],"source":["clean_pairs[:10]"]},{"cell_type":"markdown","metadata":{"id":"4Nm2z5GjcZ5L"},"source":["## Simple Word Tokenizer"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"DMd6x8_bcZ5N","executionInfo":{"status":"ok","timestamp":1751767474073,"user_tz":-600,"elapsed":73,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":["from itertools import chain"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"QlirS1FncZ5O","executionInfo":{"status":"ok","timestamp":1751767474795,"user_tz":-600,"elapsed":544,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":["# Vocab objects\n","split_eng_sent = [[\"<SOS>\"] + eng_sent.lower().strip().split() + [\"<EOS>\"]\n","                  for eng_sent, spa_sent in clean_pairs]\n","\n","\n","split_spa_sent = [[\"<SOS>\"] + spa_sent.lower().strip().split() + [\"<EOS>\"]\n","                  for eng_sent, spa_sent in clean_pairs]\n","\n","eng_vocab = set(chain.from_iterable(split_eng_sent))\n","spa_vocab = set(chain.from_iterable(split_spa_sent))\n","\n","vocab_to_ind_eng = {word: i for i, word in enumerate(eng_vocab)}\n","vocab_to_ind_spa = {word: i for i, word in enumerate(spa_vocab)}\n","\n","ind_to_word_eng = {i:w for w, i in vocab_to_ind_eng.items()}\n","ind_to_word_spa = {i:w for w, i in vocab_to_ind_spa.items()}"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Pi3RoifqcZ5O","executionInfo":{"status":"ok","timestamp":1751767475327,"user_tz":-600,"elapsed":525,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":["#Encode the sentences\n","def encode_sentence_vectors(sentence: list, vocab_to_ind: dict):\n","    return [vocab_to_ind[word] for word in sentence]\n","\n","\n","eng_senteces_encoded = [encode_sentence_vectors(sentence, vocab_to_ind_eng)\n","                        for sentence in split_eng_sent]\n","\n","spa_senteces_encoded = [encode_sentence_vectors(sentence, vocab_to_ind_spa)\n","                        for sentence in split_spa_sent]"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1751767475347,"user":{"displayName":"William Cable","userId":"04663351666127960465"},"user_tz":-600},"id":"xnBbIgxpcZ5P","outputId":"17b80f25-9027-4506-c41a-ba333e77c57d"},"outputs":[{"output_type":"stream","name":"stdout","text":["['<SOS>', 'go.', '<EOS>']\n","[8657, 8050, 17370]\n"]}],"source":["print(split_eng_sent[0])\n","print(eng_senteces_encoded[0])"]},{"cell_type":"markdown","metadata":{"id":"B41SRCLqcZ5Q"},"source":["## Create a padded dataset"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"raBPS5qQcZ5R","executionInfo":{"status":"ok","timestamp":1751767480283,"user_tz":-600,"elapsed":3823,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","\n","def pad(seq, max_len):\n","    return seq + [0]*(max_len - len(seq))\n","\n","max_eng_len = max(len(s) for s in eng_senteces_encoded)\n","max_spa_len = max(len(s) for s in spa_senteces_encoded)\n","\n","padded_eng = [pad(s, max_eng_len) for s in eng_senteces_encoded]\n","padded_spa = [pad(s, max_spa_len) for s in spa_senteces_encoded]\n","\n","class TranslationDataset(Dataset):\n","    def __init__(self, eng, spa):\n","        self.eng = eng\n","        self.spa = spa\n","\n","    def __len__(self):\n","        return len(self.eng)\n","\n","    def __getitem__(self, idx):\n","        return torch.tensor(self.eng[idx]), torch.tensor(self.spa[idx])\n","\n","\n","#Just normal batching here\n","dl = DataLoader(TranslationDataset(padded_eng, padded_spa), batch_size=32, shuffle=True)\n"]},{"cell_type":"markdown","metadata":{"id":"OtUBZ07ccZ5R"},"source":["## A model"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"FXO2Hf7IcZ5S","executionInfo":{"status":"ok","timestamp":1751767481322,"user_tz":-600,"elapsed":14,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import math\n","\n","class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super().__init__()\n","        self.dropout = nn.Dropout(dropout)\n","        pe = torch.zeros(max_len, d_model)\n","        pos = torch.arange(0, max_len).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2) * -math.log(10000.0) / d_model)\n","        pe[:, 0::2] = torch.sin(pos * div_term)\n","        pe[:, 1::2] = torch.cos(pos * div_term)\n","        self.register_buffer('pe', pe.unsqueeze(0))\n","\n","    def forward(self, x):\n","        return self.dropout(x + self.pe[:, :x.size(1)])\n"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"r4qNq9bAcZ5S","executionInfo":{"status":"ok","timestamp":1751767482233,"user_tz":-600,"elapsed":38,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":["class Seq2SeqTransformer(nn.Module):\n","    def __init__(self, num_encoder_layers, num_decoder_layers, emb_size, nhead,\n","                 src_vocab_size, tgt_vocab_size, dim_feedforward=512, dropout=0.1):\n","        super().__init__()\n","        self.src_tok_emb = nn.Embedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = nn.Embedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(emb_size, dropout)\n","\n","        self.transformer = nn.Transformer(d_model=emb_size, nhead=nhead,\n","                                          num_encoder_layers=num_encoder_layers,\n","                                          num_decoder_layers=num_decoder_layers,\n","                                          dim_feedforward=dim_feedforward,\n","                                          dropout=dropout)\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","\n","    def forward(self, src, tgt, src_mask, tgt_mask, src_pad_mask, tgt_pad_mask, mem_pad_mask):\n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(tgt))\n","        out = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask,\n","                               None, src_pad_mask, tgt_pad_mask, mem_pad_mask)\n","        return self.generator(out)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"TQMEmg9ScZ5S","executionInfo":{"status":"ok","timestamp":1751767483074,"user_tz":-600,"elapsed":25,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":["def generate_square_subsequent_mask(sz, device):\n","    return torch.triu(torch.full((sz, sz), float('-inf'), device=device), 1)\n","\n","def create_mask(src, tgt, pad_idx=0):\n","    src_seq_len = src.size(0)\n","    tgt_seq_len = tgt.size(0)\n","    device = src.device  # assume both src and tgt are on the same device\n","\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n","\n","    src_padding_mask = (src == pad_idx).transpose(0, 1)\n","    tgt_padding_mask = (tgt == pad_idx).transpose(0, 1)\n","\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2656,"status":"ok","timestamp":1751767486369,"user":{"displayName":"William Cable","userId":"04663351666127960465"},"user_tz":-600},"id":"x8FlYCFZcZ5S","outputId":"cbe214e8-5adf-48ac-a1f7-8c01209c597b"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Output shape: torch.Size([21, 32, 36000])\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py:5962: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n"]}],"source":["from itertools import chain\n","\n","# Initialize model with your vocab sizes\n","src_vocab_size = len(vocab_to_ind_eng)\n","tgt_vocab_size = len(vocab_to_ind_spa)\n","\n","model = Seq2SeqTransformer(\n","    num_encoder_layers=3,\n","    num_decoder_layers=3,\n","    emb_size=256,\n","    nhead=8,\n","    src_vocab_size=src_vocab_size,\n","    tgt_vocab_size=tgt_vocab_size,\n",")\n","\n","# One batch from your DataLoader\n","for eng_batch, spa_batch in dl:\n","    # Transpose to [seq_len, batch_size] for Transformer\n","    eng_batch = eng_batch.transpose(0, 1)\n","    spa_batch = spa_batch.transpose(0, 1)\n","\n","    # Create masks (pad_idx = 0)\n","    src_mask, tgt_mask, src_pad_mask, tgt_pad_mask = create_mask(\n","        eng_batch, spa_batch, pad_idx=0\n","    )\n","\n","    # Forward pass\n","    output = model(\n","        eng_batch,\n","        spa_batch,\n","        src_mask,\n","        tgt_mask,\n","        src_pad_mask,\n","        tgt_pad_mask,\n","        src_pad_mask  # memory key padding mask\n","    )\n","\n","    print(\"Output shape:\", output.shape)  # [tgt_seq_len, batch_size, tgt_vocab_size]\n","    break  # only one batch\n"]},{"cell_type":"markdown","metadata":{"id":"_33YYkdUcZ5T"},"source":["## Training loop"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"MHSvj9KwcZ5T","executionInfo":{"status":"ok","timestamp":1751767490321,"user_tz":-600,"elapsed":8,"user":{"displayName":"William Cable","userId":"04663351666127960465"}}},"outputs":[],"source":["def train_model(model, dataloader, optimizer, loss_fn, num_epochs, pad_idx=0, device='cpu'):\n","    model.to(device)\n","    model.train()\n","    losses = []\n","\n","    for epoch in range(num_epochs):\n","        total_loss = 0\n","        print(f\"Starting epoch {epoch}\")\n","        dl_len = len(dataloader)\n","        i = 1\n","\n","        for eng_batch, spa_batch in dataloader:\n","            print(f\"\\rStarting {i}/{dl_len}\", end=\"\")\n","            i += 1\n","            eng_batch = eng_batch.transpose(0, 1).to(device)  # [seq_len, batch]\n","            spa_batch = spa_batch.transpose(0, 1).to(device)  # [seq_len, batch]\n","\n","            tgt_input = spa_batch[:-1, :]\n","            tgt_output = spa_batch[1:, :]\n","\n","            src_mask, tgt_mask, src_pad_mask, tgt_pad_mask = create_mask(eng_batch, tgt_input, pad_idx)\n","\n","            logits = model(\n","                eng_batch,\n","                tgt_input,\n","                src_mask,\n","                tgt_mask,\n","                src_pad_mask,\n","                tgt_pad_mask,\n","                src_pad_mask  # memory padding mask\n","            )\n","\n","            optimizer.zero_grad()\n","\n","            # Flatten predictions and targets\n","            logits_flat = logits.reshape(-1, logits.shape[-1])\n","            tgt_output_flat = tgt_output.reshape(-1)\n","\n","            loss = loss_fn(logits_flat, tgt_output_flat)\n","            loss.backward()\n","            optimizer.step()\n","\n","            total_loss += loss.item()\n","\n","        avg_loss = total_loss / len(dataloader)\n","        print(f\"Epoch {epoch + 1}/{num_epochs} — Loss: {avg_loss:.4f}\")\n","        losses.append(avg_loss)\n","\n","    return losses\n"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FCwVbyWBcZ5T","executionInfo":{"status":"ok","timestamp":1751768025121,"user_tz":-600,"elapsed":530310,"user":{"displayName":"William Cable","userId":"04663351666127960465"}},"outputId":"1bac3405-2569-4c00-b4e2-d314ad31e519"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Starting epoch 0\n","Starting 3555/3555Epoch 1/5 — Loss: 4.5892\n","Starting epoch 1\n","Starting 3555/3555Epoch 2/5 — Loss: 3.2032\n","Starting epoch 2\n","Starting 3555/3555Epoch 3/5 — Loss: 2.5553\n","Starting epoch 3\n","Starting 3555/3555Epoch 4/5 — Loss: 2.1250\n","Starting epoch 4\n","Starting 3555/3555Epoch 5/5 — Loss: 1.8292\n","Model weights saved to model_weights.pth\n"]}],"source":["model = Seq2SeqTransformer(\n","    num_encoder_layers=3,\n","    num_decoder_layers=3,\n","    emb_size=256,\n","    nhead=8,\n","    src_vocab_size=len(vocab_to_ind_eng),\n","    tgt_vocab_size=len(vocab_to_ind_spa)\n",")\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)\n","loss_fn = nn.CrossEntropyLoss(ignore_index=0)\n","\n","# Train it\n","losses = train_model(model, dl, optimizer, loss_fn, num_epochs=5, pad_idx=0, device='cuda')\n","\n","# prompt: save model weights\n","\n","torch.save(model.state_dict(), \"model_weights.pth\")\n","print(\"Model weights saved to model_weights.pth\")"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":62,"status":"error","timestamp":1751792752151,"user":{"displayName":"William Cable","userId":"04663351666127960465"},"user_tz":-600},"id":"UClVgdSxcZ5U","outputId":"c989f0e2-3560-49fd-ca0d-e55be29e4864"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'losses' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1-3908220447.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training Loss Over Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'losses' is not defined"]}],"source":["import matplotlib.pyplot as plt\n","\n","plt.plot(losses)\n","plt.title(\"Training Loss Over Epochs\")\n","plt.xlabel(\"Epoch\")\n","plt.ylabel(\"Loss\")\n","plt.grid(True)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"38bXRPvIcZ5U"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qAaU7EVacZ5U"},"outputs":[],"source":["def greedy_decode(model, src_sentence, src_vocab, tgt_vocab, ind_to_word_spa, max_len=50, device='cuda'):\n","    model.eval()\n","\n","    sos_token = tgt_vocab[\"<SOS>\"]\n","    eos_token = tgt_vocab[\"<EOS>\"]\n","    pad_token = tgt_vocab.get(\"<PAD>\", 0)\n","\n","    # Encode source sentence\n","    tokens = [\"<SOS>\"] + src_sentence.lower().strip().split() + [\"<EOS>\"]\n","    src_indices = [src_vocab.get(tok, src_vocab.get(\"<UNK>\", 0)) for tok in tokens]\n","    src_tensor = torch.tensor(src_indices).unsqueeze(1).to(device)  # [seq_len, 1]\n","    src_mask = torch.zeros((src_tensor.size(0), src_tensor.size(0)), device=device).type(torch.bool)\n","\n","    # Encoder output\n","    src_emb = model.positional_encoding(model.src_tok_emb(src_tensor))\n","    memory = model.transformer.encoder(src_emb, src_mask)\n","\n","    # Start decoding with <SOS>\n","    tgt_indices = [sos_token]\n","    for _ in range(max_len):\n","        tgt_tensor = torch.tensor(tgt_indices).unsqueeze(1).to(device)\n","        tgt_mask = generate_square_subsequent_mask(tgt_tensor.size(0), 'cuda')#s.to(device)\n","\n","        tgt_emb = model.positional_encoding(model.tgt_tok_emb(tgt_tensor))\n","        out = model.transformer.decoder(tgt_emb, memory, tgt_mask)\n","        out = model.generator(out)\n","\n","        next_token = out[-1].argmax(-1).item()\n","\n","        if next_token == eos_token:\n","            break\n","\n","        tgt_indices.append(next_token)\n","\n","    decoded = [ind_to_word_spa.get(idx, \"\") for idx in tgt_indices[1:]]  # skip SOS\n","    return \" \".join(decoded)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"clSl2tVwcZ5U"},"outputs":[],"source":["def translate(eng_sentence, model, src_vocab, tgt_vocab, ind_to_word_spa):\n","    return greedy_decode(model, eng_sentence, src_vocab, tgt_vocab, ind_to_word_spa)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"elapsed":55,"status":"error","timestamp":1751539268109,"user":{"displayName":"William Cable","userId":"04663351666127960465"},"user_tz":-600},"id":"ci0rPksOcZ5U","outputId":"cde8b044-68fc-4687-aeab-fc9952e6cc21"},"outputs":[{"ename":"NameError","evalue":"name 'translate' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1-4093756756.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I'm very excited to have dinner with you\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_to_ind_eng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab_to_ind_spa\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mind_to_word_spa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'translate' is not defined"]}],"source":["print(translate(\"I'm very excited to have dinner with you\", model, vocab_to_ind_eng, vocab_to_ind_spa, ind_to_word_spa))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6lzFURBUcZ5X"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LqnJa7UpcZ5Y"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ToGWwYpMcZ5Y"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wiMOD0RRcZ5Z"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}